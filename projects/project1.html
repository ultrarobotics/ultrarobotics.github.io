<div class="project-slide active" id="project1">
                  
  <!-- Embedded YouTube Video -->
  <div class="video-container">
    <iframe 
      src="https://www.youtube.com/embed/ncXCRyfIYDc?autoplay=1&mute=1&loop=1&playlist=ncXCRyfIYDc&controls=1&modestbranding=1&rel=0" 
      title="MSc Thesis: Co-design of Quadruped Using Reinforcement Learning Video" 
      frameborder="0" 
      allow="autoplay; encrypted-media" 
      allowfullscreen>
    </iframe>
  </div>
  
  <!-- Thesis Content with Images Side by Side -->
  <div class="thesis-container">
    <div class="thesis-text">
      <h4>MSc Thesis: Co-design of Quadruped Using Reinforcement Learning (in progress)</h4>
      <p>
        During my master’s studies and personal projects building robots, I encountered the challenges of designing robots that perform effectively in real-world scenarios. These experiences inspired me to focus my self-proposed thesis on learning-based co-design. Co-design is a promising approach that optimizes a robot’s physical design and motion simultaneously, simplifying the process of creating high-performance robotic systems.
      </p>
      <p>
        In my thesis, I made a co-design algorithm using <strong> Reinforcement Learning (RL) </strong> and applied it to a quadruped robot. I also build a modular hardware platform <strong>from scratch</strong> to implement the optimzed designs on.
      </p>
    
      <ul>
        <li><strong>Designing the Robot:</strong>
          <ul class="sub-bullet">
            <li>Defined platform requirements with a focus on modularity, torque-controlled motors, and cost-efficiency.</li>
            <li>Selected electronic and mechanical components, negotiating discounts with suppliers.</li>
            <li>Designed the robot with modularity and manufacturability in mind to easily test various co-optimized designs.</li>
            <li>Created a comprehensive CAD model in SolidWorks and prototyped subcomponents such as the legs, compute module, and body layout.</li>
            <li>Developed a modular design space (details to be announced soon).</li>
          </ul>
        </li>
        <li><strong>Building the Robot:</strong>
          <ul class="sub-bullet">
            <li>Fabricated all parts using my Creality CR-10 3D printer.</li>
            <li>Hand-crafted wiring with soldering tools and heat guns.</li>
            <li>Tested electronics using professional-grade equipment, including a power supply, multimeter, and oscilloscope.</li>
          </ul>
        </li>
        <li><strong>Developing Low-Level Software:</strong>
          <ul class="sub-bullet">
            <li>Enhanced C++ packages to integrate with my custom software stack for I²C communication with the MPU6050 IMU in DMP mode, reducing computation on the NVIDIA Jetson platform.</li>
            <li>Built asynchronous Python-based bi-directional CAN communication for Xiaomi Cybergears motors, translating technical documentation from a Chinese manual.</li>
            <li>Automated the initialization of the IMU and PEAK CAN devices using Linux services.</li>
            <li>Configured NVIDIA JetPack with all necessary drivers and packages.</li>
          </ul>
        </li>
        <li><strong>Simulating the Robot:</strong>
          <ul class="sub-bullet">
            <li>Exported the robot’s CAD design from SolidWorks to URDF and converted it to MJCF for simulation.</li>
            <li>Created a realistic robot model by measuring part weights and consulting motor datasheets.</li>
            <li>Developed code functions to easily select designs within the modular design space, enabling automated robot model updates.</li>
          </ul>
        </li>
        <li><strong>Creating a Reinforcement Learning-Based Co-Design Algorithm:</strong>
          <ul class="sub-bullet">
            <li>Built a parallelizable RL environment using MuJoCo (MJX) and Brax.</li>
            <li>Trained locomotion policies using Brax’s JAX-based PPO algorithm for flat and rough terrains, exploring gaits such as trotting and pronking.</li>
            <li>Designed a co-design algorithm leveraging RL principles (further details to be announced).</li>
          </ul>
        </li>
        <li><strong>Setting Up Reinforcement Learning Training Infrastructure:</strong>
          <ul class="sub-bullet">
            <li>Streamlined the training process with an optimized RL training pipeline.</li>
            <li>Created configuration files for efficient training and evaluation workflows.</li>
            <li>Automated tools for monitoring training progress through real-time plotting.</li>
          </ul>
        </li>
        <li><strong>Sim-to-Real: Transferring Policies to the Real Robot:</strong>
          <ul class="sub-bullet">
            <li>Improved sim-to-real transfer using domain randomization, sensor noise injection, and disturbance modeling.</li>
            <li>Conducted sim-to-sim policy transfers to test locomotion via a gamepad.</li>
            <li>Built scripts to convert trained JAX models to PyTorch and ONNX formats for use in simulation and on the real robot.</li>
            <li>Leveraged TensorRT and PyCUDA to enable efficient neural network inference on the NVIDIA Jetson platform.</li>
          </ul>
        </li>
      </ul>
      
      <p>
        Through this project, I combined my passion for designing robots with my interest in learning-based optimization, resulting in a modular platform that integrates co-optimized designs with real-world deployment. My approach exemplifies how a synergy between hardware and AI algorithms can push the boundaries of robotic performance in complex environments.
      </p>
    </div>
    <div class="thesis-images">
      <div class="project-gallery">
        <img src="images/project1-img1.jpg" alt="Project Image 1">
        <img src="images/project1-img2.jpg" alt="Project Image 2">
        <img src="images/project1-img3.jpg" alt="Project Image 3">
        <img src="images/project1-img4.png" alt="Project Image 4">
      </div>
    </div>
  </div>
</div>