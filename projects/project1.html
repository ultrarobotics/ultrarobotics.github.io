<div class="project-slide active" id="project1">
                  
  <!-- Embedded YouTube Video -->
  <div class="video-container">
    <iframe 
      src="https://www.youtube.com/embed/ncXCRyfIYDc?autoplay=1&mute=1&loop=1&playlist=ncXCRyfIYDc&controls=1&modestbranding=1&rel=0" 
      title="MSc Thesis: Co-design of Quadruped Using Reinforcement Learning Video" 
      frameborder="0" 
      allow="autoplay; encrypted-media" 
      allowfullscreen>
    </iframe>
  </div>
  
  <!-- Thesis Content with Images Side by Side -->
  <div class="thesis-container">
    <div class="thesis-text">
      <h4>MSc Thesis: Co-design of a Quadruped using Reinforcement Learning</h4>
      <p class="project-date">11-2023 – 01-2025</p>
      <p>
        During my personal hobby projects were I build robots, I encountered the challenges of designing designing physical robots and their motions so that they can perform effectively in real-world scenarios. These experiences inspired me to pursue a thesis on learning-based co-design. Co-design is an approach that optimizes a robot’s physical design and motion simultaneously, thereby simplifying the process of creating high-performance robotic systems.
      </p>
      <p>
        In my thesis, I developed a co-design algorithm using <strong> Reinforcement Learning (RL) </strong> and applied it to a quadruped robot. I also built a modular hardware platform <strong>from scratch</strong> to implement the optimzed designs on. Below are some of the important steps I took during the project:
      </p>
    
      <ul>
        <li><strong>Designing the Robot:</strong>
          <ul class="sub-bullet">
            <li>Defined platform requirements with a focus on modularity, torque-controlled motors, and cost-efficiency.</li>
            <li>Selected electronic and mechanical components, where I discussed and got discounts from suppliers.</li>
            <li>Designed the robot with modularity and manufacturability in mind to easily test various co-optimized designs.</li>
            <li>Created the CAD model in SolidWorks.</li>
            <li>Prototyped subcomponents such as the legs, compute module, and body layout.</li>
          </ul>
        </li>
        <li><strong>Building the Robot:</strong>
          <ul class="sub-bullet">
            <li>Fabricated all parts using my Creality CR-10 3D printer.</li>
            <li>Handcrafted the wires by using soldering tools.</li>
            <li>Tested electronics using equipment such as a power supply, multimeter, and oscilloscope.</li>
          </ul>
        </li>
        <li><strong>Developing Low-Level Software:</strong>
          <ul class="sub-bullet">
            <li>Enhanced C++ packages to integrate with my custom software stack for I²C communication with the MPU6050 IMU in DMP mode, reducing computation on the NVIDIA Jetson platform.</li>
            <li>Built asynchronous Python-based bi-directional CAN communication for Xiaomi Cybergears motors, with the help of technical documentation from the Chinese manual.</li>
            <li>Configured NVIDIA JetPack with all necessary drivers and packages.</li>
            <li>Automated the initialization of the IMU and PEAK CAN devices using Linux services and bash scripts.</li>
            <li>Implemented a state machine for robot start-up, calibration, walking and sitting states.</li>
          </ul>
        </li>
        <li><strong>Simulating the Robot:</strong>
          <ul class="sub-bullet">
            <li>Exported the robot’s CAD design from SolidWorks to URDF and converted it to MJCF for simulation.</li>
            <li>Created a realistic robot model by measuring part weights and extracting details from motor datasheets.</li>
            <li>Developed functions in the simulator to easily select designs within the modular design space.</li>
          </ul>
        </li>
        <li><strong>Creating a Reinforcement Learning-Based Co-Design Algorithm:</strong>
          <ul class="sub-bullet">
            <li>Built a parallelizable RL environment using MuJoCo (MJX) and Brax.</li>
            <li>Trained locomotion policies using Brax’s JAX-based PPO algorithm for flat and rough terrains, exploring gaits such as trotting and pronking.</li>
            <li>Designed a co-design algorithm that uses the RL locomotion policies (further details to be announced).</li>
          </ul>
        </li>
        <li><strong>Setting Up Reinforcement Learning Training Infrastructure:</strong>
          <ul class="sub-bullet">
            <li>Streamlined the training process with RL training and deployment infrastructure.</li>
            <li>Created configuration files for training and evaluation workflows.</li>
            <li>Automated tools for monitoring training progress through automated plots.</li>
            <li>Conducted sim-to-sim policy transfers to test locomotion via a gamepad.</li>
            <li>Built scripts to convert trained JAX models to NVIDIA TensorRT format (via PyTorch and ONNX) for efficient inference on the real robot and simulation environments.</li>
          </ul>
        </li>
        <li><strong>Sim-to-Real: Transferring Policies to the Real Robot:</strong>
          <ul class="sub-bullet">
            <li>Improved sim-to-real transfer using domain randomization, sensor noise injection, and disturbance modeling, modelled from real-world data.</li>
            <li>Used similar style configuration files on the robot to quickly test different policies with different configurations.</li>
            <li>Leveraged TensorRT and PyCUDA to enable efficient neural network inference on the NVIDIA Jetson platform.</li>
            <li>Created a wireless connection via TCP between the laptop and the robot, that sends the controller command to robot, and where the robot shares its state to the laptop where all data is logged.</li>
            <li>Programmed an autopilot mode that automatically sends commands on fixed sequences to ensure that testing is fair between designs.</li>
          </ul>
        </li>
        <li><strong>Results (further details to be announced):</strong>
          <ul class="sub-bullet">
            <li>Experiments show that co-optimized designs are significantly efficient in locomotion compared to nominal designs for various tasks.</li>
          </ul>
        </li>
      </ul>
      
      <p>
        Throughout this project, I combined my passion for designing robots with my interest in learning-based optimization, resulting in a modular platform that integrates co-optimized designs in the real-world. My approach exemplifies how a synergy between hardware and AI algorithms can push the boundaries of robotic performance in complex environments.
      </p>
    </div>
    <div class="thesis-images">
      <div class="project-gallery">
        <img src="images/project1-img1.jpg" alt="Project Image 1">
        <img src="images/project1-img2.jpg" alt="Project Image 2">
        <img src="images/project1-img3.jpg" alt="Project Image 3">
        <img src="images/project1-img4.png" alt="Project Image 4">
      </div>
    </div>
  </div>
</div>