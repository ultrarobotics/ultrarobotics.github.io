<div class="project-slide active" id="project1">
                  
  <!-- Embedded YouTube Video -->
  <div class="video-container">
    <iframe 
      src="https://www.youtube.com/embed/ncXCRyfIYDc?autoplay=1&mute=1&loop=1&playlist=ncXCRyfIYDc&controls=1&modestbranding=1&rel=0" 
      title="MSc Thesis: Co-design of Quadruped Using Reinforcement Learning Video" 
      frameborder="0" 
      allow="autoplay; encrypted-media" 
      allowfullscreen>
    </iframe>
  </div>
  
  <!-- Thesis Content with Images Side by Side -->
  <div class="thesis-container">
    <div class="thesis-text">
      <h4>MSc Thesis: Co-Design of a Quadruped using Reinforcement Learning</h4>
      <p class="project-date">Duration: November 2023 – January 2025</p>
      <p>
        Through my experience developing robots as hobby projects, I encountered the challenges of both designing the physical hardware of a robot and controlling it effectively. What makes this challenging is the intricate relationship between a robot’s design and its control strategy. For instance, a quadruped with shorter legs must take quicker steps to match the speed of a longer-legged counterpart—but which design yields optimal performance for a given task?
      </p>
      <p>
        My thesis explores <strong>learning-based co-design</strong>, an approach that simultaneously optimizes a robot’s hardware and control policies. Specifically, I develop a co-design algorithm integrating <strong>Reinforcement Learning (RL) and Bayesian Optimization (BO)</strong> to generate efficient quadruped designs and motions. To validate these designs, I built <strong>a modular quadruped from scratch</strong> and addressed the <strong>sim-to-real</strong> transfer challenge, ensuring that both the learned locomotion policies and co-optimized designs function effectively in real-world conditions.
      </p>
      <p>
        Currently, I am preparing a paper based on this work. Below are key aspects of the project:
      </p>

      <h5>Hardware Development: Designing and Building the Robot</h5>
      <ul>
        <li>Defined platform requirements focusing on modularity, torque-controlled motors, and cost-efficiency.</li>
        <li>Selected electronic and mechanical components while negotiating supplier discounts.</li>
        <li><strong>Designed a modular quadruped from scratch</strong>, ensuring ease of manufacturability and assembly.</li>
        <li>Used SolidWorks to design parts and fabricated them using a Creality CR-10 3D printer and handcrafted wiring using soldering tools.</li>
        <li>Prototyped and tested key components, including legs, compute modules, and body layout.</li>
        <li>Assembled and tested electronics with power supplies, multimeters, and oscilloscopes.</li>
      </ul>

      <h5>Software Development: Low-Level Control & System Integration</h5>
      <ul>
        <li>Modified C++ drivers for I²C communication with an MPU6050 IMU (DMP mode) to reduce computational load on the <strong>NVIDIA Jetson</strong>.</li>
        <li>Built a Python-based asynchronous bi-directional CAN communication system for Xiaomi Cybergears motors.</li>
        <li>Integrated TensorRT and PyCUDA for high-efficiency neural network inference on the NVIDIA Jetson platform.</li>
        <li>Automated system initialization via Linux services and bash scripts for IMU and PEAK CAN devices.</li>
        <li>Designed a state machine for robot startup, calibration, locomotion, and sitting states.</li>
      </ul>

      <h5>Simulation & Reinforcement Learning-Based Co-Design</h5>
      <ul>
        <li>Converted the CAD model from SolidWorks → URDF → MJCF for simulation in MuJoCo (MJX).</li>
        <li>Created a realistic robot model by measuring part weights and using motor specifications.</li>
        <li><strong>Developed an RL training environment for parallelized simulations, enabling quick policy learning using MuJoCo (MJX) and Brax.</strong></li>
        <li>Trained locomotion policies using Brax’s JAX-based PPO algorithm, exploring gaits such as trotting and pronking on both flat and rough terrains.</li>
        <li>Implemented a co-design algorithm that jointly optimizes the robot’s physical design and motion using RL policies and Bayesian Optimization.</li>
      </ul>

      <h5>Reinforcement Learning Training Infrastructure</h5>
      <ul>
        <li><strong>Streamlined RL training and deployment with automated pipelines.</strong></li>
        <li>Created configuration files to standardize training and evaluation workflows.</li>
        <li>Built monitoring tools to track training progress and policy performance.</li>
        <li>Conducted sim-to-sim policy transfers for testing locomotion policies via a gamepad.</li>
        <li>Developed conversion scripts to export trained JAX models to NVIDIA TensorRT (via PyTorch & ONNX) for real-time deployment.</li>
      </ul>

      <h5>Sim-to-Real: Deploying Policies on the Physical Robot</h5>
      <ul>
        <li><strong>Improved sim-to-real transfer using domain randomization, sensor noise injection, and disturbance modeling.</strong></li>
        <li>Designed configuration files on the robot for rapid deployment of different policies.</li>
        <li>Established a wireless TCP communication link between the robot and a laptop for real-time control and logging.</li>
        <li>Built a UI for real-time visualization of robot state data, enabling faster debugging of sim-to-real inconsistencies.</li>
        <li>Developed an autopilot mode that executes fixed command sequences for controlled and repeatable experiments.</li>
      </ul>

      <h5>Results & Insights</h5>
      <ul>
        <li><strong>Experiments demonstrate that co-optimized designs significantly outperform nominal designs in locomotion efficiency across various tasks in the real-world.</strong></li>
        <li>Further details will be presented in the forthcoming publication.</li>
      </ul>

      <h5>Closing Thoughts</h5>
      <ul>
        <li>My thesis combines <strong>my passions for robot design and AI-driven control</strong>, demonstrating how co-design methodologies can push the boundaries of robotic performance. By integrating hardware optimization with machine learning, my work contributes to the future of performant robotic systems.
        <li>I am currently preparing a research paper based on this work. <strong>If you're interested in discussing co-design, reinforcement learning, or legged locomotion, feel free to send me a message on LinkedIn! </strong></li>
      </ul>
    </div>
    <div class="thesis-images">
      <div class="project-gallery">
        <img src="images/project1-img1.jpg" alt="Project Image 1">
        <img src="images/project1-img2.jpg" alt="Project Image 2">
        <img src="images/project1-img3.jpg" alt="Project Image 3">
        <img src="images/project1-img4.png" alt="Project Image 4">
      </div>
    </div>
  </div>
</div>
