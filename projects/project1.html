<div class="project-slide active" id="project1">
                  
  <!-- Embedded YouTube Video -->
  <div class="video-container">
    <iframe 
      src="https://www.youtube.com/embed/ncXCRyfIYDc?autoplay=1&mute=1&loop=1&playlist=ncXCRyfIYDc&controls=1&modestbranding=1&rel=0" 
      title="MSc Thesis: Co-design of Quadruped Using Reinforcement Learning Video" 
      frameborder="0" 
      allow="autoplay; encrypted-media" 
      allowfullscreen>
    </iframe>
  </div>
  
  <!-- Thesis Content with Images Side by Side -->
  <div class="thesis-container">
    <div class="thesis-text">
      <h4>MSc Thesis: Co-design of Quadruped Using Reinforcement Learning (in progress)</h4>
      <p>
        During my master’s studies and personal projects building robots, I encountered the challenges of designing robots that perform effectively in real-world scenarios. These experiences inspired me to focus my self-proposed thesis on learning-based co-design. Co-design is an approach that optimizes a robot’s physical design and motion simultaneously, simplifying the process of creating high-performance robotic systems.
      </p>
      <p>
        In my thesis, I made a co-design algorithm using <strong> Reinforcement Learning (RL) </strong> and applied it to a quadruped robot. I also build a modular hardware platform <strong>from scratch</strong> to implement the optimzed designs on.
      </p>
    
      <ul>
        <li><strong>Designing the Robot:</strong>
          <ul class="sub-bullet">
            <li>Defined platform requirements with a focus on modularity, torque-controlled motors, and cost-efficiency.</li>
            <li>Selected electronic and mechanical components, where I discussed and got discounts from suppliers.</li>
            <li>Designed the robot with modularity and manufacturability in mind to easily test various co-optimized designs.</li>
            <li>Created the CAD model in SolidWorks</li>
            <li>Prototyped subcomponents such as the legs, compute module, and body layout.</li>
          </ul>
        </li>
        <li><strong>Building the Robot:</strong>
          <ul class="sub-bullet">
            <li>Fabricated all parts using my Creality CR-10 3D printer.</li>
            <li>Hand-crafted the wires by using soldering tools.</li>
            <li>Tested electronics using equipment such as a power supply, multimeter, and oscilloscope.</li>
          </ul>
        </li>
        <li><strong>Developing Low-Level Software:</strong>
          <ul class="sub-bullet">
            <li>Enhanced C++ packages to integrate with my custom software stack for I²C communication with the MPU6050 IMU in DMP mode, reducing computation on the NVIDIA Jetson platform.</li>
            <li>Built asynchronous Python-based bi-directional CAN communication for Xiaomi Cybergears motors, with the help of a technical documentation from the Chinese manual.</li>
            <li>Configured NVIDIA JetPack with all necessary drivers and packages.</li>
            <li>Automated the initialization of the IMU and PEAK CAN devices using Linux services and bash scripts.</li>
          </ul>
        </li>
        <li><strong>Simulating the Robot:</strong>
          <ul class="sub-bullet">
            <li>Exported the robot’s CAD design from SolidWorks to URDF and converted it to MJCF for simulation.</li>
            <li>Created a realistic robot model by measuring part weights and consulting motor datasheets.</li>
            <li>Developed code functions in the simulator to easily select designs within the modular design space.</li>
          </ul>
        </li>
        <li><strong>Creating a Reinforcement Learning-Based Co-Design Algorithm:</strong>
          <ul class="sub-bullet">
            <li>Built a parallelizable RL environment using MuJoCo (MJX) and Brax.</li>
            <li>Trained locomotion policies using Brax’s JAX-based PPO algorithm for flat and rough terrains, exploring gaits such as trotting and pronking.</li>
            <li>Designed a co-design algorithm that uses the RL locomotion policies (further details to be announced).</li>
          </ul>
        </li>
        <li><strong>Setting Up Reinforcement Learning Training Infrastructure:</strong>
          <ul class="sub-bullet">
            <li>Streamlined the training process with RL training and deployment infrastucture.</li>
            <li>Created configuration files for training and evaluation workflows.</li>
            <li>Automated tools for monitoring training progress through automated plots.</li>
            <li>Conducted sim-to-sim policy transfers to test locomotion via a gamepad.</li>
            <li>Built scripts to convert trained JAX models to PyTorch and ONNX formats for use in simulation and on the real robot.</li>
          </ul>
        </li>
        <li><strong>Sim-to-Real: Transferring Policies to the Real Robot:</strong>
          <ul class="sub-bullet">
            <li>Improved sim-to-real transfer using domain randomization, sensor noise injection, and disturbance modeling, modelled from real-world data.</li>
            <li>Used similar style configuration files on the robot to quickly test different policies with different configurations.</li>
            <li>Leveraged TensorRT and PyCUDA to enable efficient neural network inference on the NVIDIA Jetson platform.</li>
            <li>Created a wireless connection via TCP between laptop and robot, that sends the controller command to robot, and where the robot shares its state to the laptop where all data is logged.</li>
          </ul>
        </li>
        <li><strong>Results (further details to be announced):</strong>
          <ul class="sub-bullet">
            <li>Early tests show that co-optimized designs are more efficient in locomotion compared to nominal designs.</li>
          </ul>
        </li>
      </ul>
      
      <p>
        Throughout this project, I combined my passion for designing robots with my interest in learning-based optimization, resulting in a modular platform that integrates co-optimized designs in the real-world. My approach exemplifies how a synergy between hardware and AI algorithms can push the boundaries of robotic performance in complex environments.
      </p>
    </div>
    <div class="thesis-images">
      <div class="project-gallery">
        <img src="images/project1-img1.jpg" alt="Project Image 1">
        <img src="images/project1-img2.jpg" alt="Project Image 2">
        <img src="images/project1-img3.jpg" alt="Project Image 3">
        <img src="images/project1-img4.png" alt="Project Image 4">
      </div>
    </div>
  </div>
</div>